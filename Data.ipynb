{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f6c1599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-07T12:11:09.646476400Z",
     "start_time": "2023-05-07T12:11:06.692702300Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.trend import MACD\n",
    "from ta.momentum import RSIIndicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8e3b35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('btcusd.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db45167a",
   "metadata": {},
   "source": [
    "# Getting data from the metatrader server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b052294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(symbol):\n",
    "\n",
    "    # Getting data on the 1 hour timeframe\n",
    "    if not mt5.initialize():\n",
    "        print(\"initialize() failed, error code =\",mt5.last_error())\n",
    "        quit()\n",
    "\n",
    "    # set the symbol and timefram\n",
    "    timeframe = mt5.TIMEFRAME_H1   # for one-minute bars\n",
    "\n",
    "    #dates for retrieving the history\n",
    "    date_from = datetime(2016, 12, 15)\n",
    "    today = datetime.today()\n",
    "\n",
    "    # get the history\n",
    "    history = mt5.copy_rates_range(symbol, timeframe, date_from, today)\n",
    "\n",
    "    if history is not None and len(history) > 0:\n",
    "        # create DataFrame out of the obtained data\n",
    "        rates_frame = pd.DataFrame(history).drop(['spread','real_volume'], axis =1)\n",
    "\n",
    "        # convert time in seconds into the datetime format\n",
    "        rates_frame['time'] = pd.to_datetime(rates_frame['time'], unit='s')\n",
    "    else:\n",
    "        print(\"No data for the requested period\")\n",
    "\n",
    "    # terminate the connection to the MetaTrader 5 terminal\n",
    "    mt5.shutdown()\n",
    "    \n",
    "    data =rates_frame\n",
    "\n",
    "    return data\n",
    "\n",
    "data =get_data('XAUUSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a1f20395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_indicators(df):\n",
    "    \n",
    "    # Calculate the moving averages\n",
    "    df['MA_daily'] = df['close'].rolling(window=50).mean()\n",
    "    df['MA_weekly'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "    # Calculate the Relative Strength Index (RSI)\n",
    "    rsi_indicator = RSIIndicator(df['close'])\n",
    "    df['RSI'] = rsi_indicator.rsi()\n",
    "\n",
    "    # Calculate Bollinger Bands\n",
    "    bollinger = BollingerBands(df['close'])\n",
    "    df['BB_High'] = bollinger.bollinger_hband()\n",
    "    df['BB_Low'] = bollinger.bollinger_lband()\n",
    "    df['BBW'] = df['BB_High'] - df['BB_Low']\n",
    "\n",
    "    # Calculate MACD\n",
    "    macd_indicator = MACD(df['close'])\n",
    "    df['MACD'] = macd_indicator.macd()\n",
    "\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e2164e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_signal(df):\n",
    "    # RSI rules\n",
    "    df['RSI_signal'] = 0\n",
    "    df.loc[df['RSI'] > 70, 'RSI_signal'] = 1\n",
    "    df.loc[df['RSI'] < 30, 'RSI_signal'] = -1\n",
    "    # Bollinger Bands rules\n",
    "    df['BB_signal'] = 0\n",
    "    df.loc[df['close'] > df['BB_High'], 'BB_signal'] = 1\n",
    "    df.loc[df['close'] < df['BB_Low'], 'BB_signal'] = -1\n",
    "    # MACD rules\n",
    "    df['MACD_signal'] = 0\n",
    "    df.loc[df['MACD'] > 0, 'MACD_signal'] = 1\n",
    "    df.loc[df['MACD'] < 0, 'MACD_signal'] = -1\n",
    "    # Moving Averages rules\n",
    "    df['MA_signal'] = 0\n",
    "    df.loc[df['close'] > df['MA_daily'], 'MA_signal'] = 1\n",
    "    df.loc[df['close'] < df['MA_daily'], 'MA_signal'] = -1\n",
    "    \n",
    "    #engulfing signal \n",
    "    df['Engulfing'] = 0\n",
    "    for i in range(1, len(df)):\n",
    "        # Bullish engulfing condition\n",
    "        if df.loc[i-1, 'open'] > df.loc[i-1, 'close'] and df.loc[i, 'open'] < df.loc[i, 'close'] and df.loc[i-1, 'open'] < df.loc[i, 'close'] and df.loc[i-1, 'close'] > df.loc[i, 'open']:\n",
    "            df.loc[i, 'Engulfing'] = 1\n",
    "\n",
    "        # Bearish engulfing condition\n",
    "        elif df.loc[i-1, 'open'] < df.loc[i-1, 'close'] and df.loc[i, 'open'] > df.loc[i, 'close'] and df.loc[i-1, 'open'] > df.loc[i, 'close'] and df.loc[i-1, 'close'] < df.loc[i, 'open']:\n",
    "            df.loc[i, 'Engulfing'] = -1\n",
    "    \n",
    "    # Remove nas\n",
    "#     data = df.dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60b4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_consolidations_and_breakouts(df):\n",
    "    # initialize new columns\n",
    "    df['Consolidation'] = 0\n",
    "    df['Breakout'] = 0\n",
    "\n",
    "    consolidation_start = None\n",
    "\n",
    "    # calculate BBW and ATR\n",
    "    df['BBW'] = df['BB_High'] - df['BB_Low']\n",
    "    df['HL'] = df['high'] - df['low']\n",
    "    df['HPC'] = abs(df['high'] - df['close'].shift())\n",
    "    df['LPC'] = abs(df['low'] - df['close'].shift())\n",
    "    df['TR'] = df[['HL', 'HPC', 'LPC']].max(axis=1)\n",
    "    df['ATR'] = df['TR'].rolling(window=14).mean()\n",
    "    df.drop(['HL', 'HPC', 'LPC', 'TR'], axis=1, inplace=True)  # remove temporary columns\n",
    "\n",
    "    # threshold values for BBW and ATR \n",
    "    bbw_threshold = df['BBW'].quantile(0.2)  # for example, the 20th percentile\n",
    "    atr_threshold = df['ATR'].quantile(0.2)  # for example, the 20th percentile\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        # check for start of consolidation\n",
    "        if (df.loc[i, 'BBW'] < bbw_threshold and\n",
    "            df.loc[i, 'ATR'] < atr_threshold and\n",
    "            (df.loc[i, 'RSI'] > 30 and df.loc[i, 'RSI'] < 70)):\n",
    "            consolidation_start = i\n",
    "            df.loc[i, 'Consolidation'] = 1\n",
    "\n",
    "        # check for end of consolidation\n",
    "        elif consolidation_start is not None:\n",
    "            max_high_during_consolidation = df.loc[consolidation_start:i, 'high'].max()\n",
    "            min_low_during_consolidation = df.loc[consolidation_start:i, 'low'].min()\n",
    "            avg_volume_during_consolidation = df.loc[consolidation_start:i, 'tick_volume'].mean()\n",
    "            current_volume = df.loc[i, 'tick_volume']\n",
    "\n",
    "            if df.loc[i, 'high'] > max_high_during_consolidation and current_volume > avg_volume_during_consolidation:\n",
    "                df.loc[i, 'Breakout'] = 1  # upward breakout\n",
    "                consolidation_start = None  # reset for the next consolidation\n",
    "\n",
    "            elif df.loc[i, 'low'] < min_low_during_consolidation and current_volume > avg_volume_during_consolidation:\n",
    "                df.loc[i, 'Breakout'] = -1  # downward breakout\n",
    "                consolidation_start = None  # reset for the next consolidation\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "87240a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_consolidations_and_breakouts(df, min_consolidation_length=3):\n",
    "    # initialize new columns\n",
    "    df['Consolidation'] = 0\n",
    "    df['Breakout'] = 0\n",
    "\n",
    "    consolidation_start = None\n",
    "    consolidation_length = 0\n",
    "\n",
    "    # calculate BBW and ATR\n",
    "    df['BBW'] = df['BB_High'] - df['BB_Low']\n",
    "    df['HL'] = df['high'] - df['low']\n",
    "    df['HPC'] = abs(df['high'] - df['close'].shift())\n",
    "    df['LPC'] = abs(df['low'] - df['close'].shift())\n",
    "    df['TR'] = df[['HL', 'HPC', 'LPC']].max(axis=1)\n",
    "    df['ATR'] = df['TR'].rolling(window=14).mean()\n",
    "    df.drop(['HL', 'HPC', 'LPC', 'TR'], axis=1, inplace=True)  # remove temporary columns\n",
    "\n",
    "    # threshold values for BBW and ATR \n",
    "    bbw_threshold = df['BBW'].quantile(0.2)  # for example, the 20th percentile\n",
    "    atr_threshold = df['ATR'].quantile(0.2)  # for example, the 20th percentile\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        # check for start of consolidation\n",
    "        if (df.loc[i, 'BBW'] < bbw_threshold and\n",
    "            df.loc[i, 'ATR'] < atr_threshold and\n",
    "            (df.loc[i, 'RSI'] > 30 and df.loc[i, 'RSI'] < 70)):\n",
    "            if consolidation_start is None:\n",
    "                consolidation_start = i\n",
    "            consolidation_length += 1\n",
    "            df.loc[i, 'Consolidation'] = 1\n",
    "\n",
    "        # check for end of consolidation\n",
    "        elif consolidation_start is not None and consolidation_length >= min_consolidation_length:\n",
    "            max_high_during_consolidation = df.loc[consolidation_start:i, 'high'].max()\n",
    "            min_low_during_consolidation = df.loc[consolidation_start:i, 'low'].min()\n",
    "            avg_volume_during_consolidation = df.loc[consolidation_start:i, 'tick_volume'].mean()\n",
    "            current_volume = df.loc[i, 'tick_volume']\n",
    "\n",
    "            if df.loc[i, 'high'] > max_high_during_consolidation and current_volume > avg_volume_during_consolidation:\n",
    "                df.loc[i, 'Breakout'] = 1  # upward breakout\n",
    "                consolidation_start = None  # reset for the next consolidation\n",
    "                consolidation_length = 0\n",
    "\n",
    "            elif df.loc[i, 'low'] < min_low_during_consolidation and current_volume > avg_volume_during_consolidation:\n",
    "                df.loc[i, 'Breakout'] = -1  # downward breakout\n",
    "                consolidation_start = None  # reset for the next consolidation\n",
    "                consolidation_length = 0\n",
    "\n",
    "        else:\n",
    "            consolidation_start = None  # reset for the next consolidation\n",
    "            consolidation_length = 0\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "31e56854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_consolidation_breakout_indicator(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # initialize new columns\n",
    "    df['Consolidation_wv'] = 0\n",
    "    df['Breakout_wv'] = 0\n",
    "\n",
    "    consolidation_start = None\n",
    "\n",
    "    for i in range(2, len(df)):\n",
    "        # check for start of consolidation\n",
    "        if abs(df.loc[i, 'high'] - df.loc[i, 'low']) <= abs(df.loc[i-1, 'high'] - df.loc[i-1, 'low']) and abs(df.loc[i-1, 'high'] - df.loc[i-1, 'low']) <= abs(df.loc[i-2, 'high'] - df.loc[i-2, 'low']):\n",
    "            consolidation_start = i\n",
    "            df.loc[i, 'Consolidation_wv'] = 1\n",
    "\n",
    "        # check for end of consolidation\n",
    "        elif consolidation_start is not None:\n",
    "            max_high_during_consolidation = df.loc[consolidation_start:i, 'high'].max()\n",
    "            min_low_during_consolidation = df.loc[consolidation_start:i, 'low'].min()\n",
    "\n",
    "            if df.loc[i, 'high'] > max_high_during_consolidation or df.loc[i, 'low'] < min_low_during_consolidation:\n",
    "                df.loc[i, 'Breakout_wv'] = 1\n",
    "                consolidation_start = None  # reset for the next consolidation\n",
    "\n",
    "    return df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "caad79e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[137], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39mapply_indicators(data)\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m\u001b[43mindicator_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m datam \u001b[38;5;241m=\u001b[39m detect_consolidations_and_breakouts(data)\n\u001b[0;32m      4\u001b[0m data\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[91], line 23\u001b[0m, in \u001b[0;36mindicator_signal\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEngulfing\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Bullish engulfing condition\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m df\u001b[38;5;241m.\u001b[39mloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     24\u001b[0m         df\u001b[38;5;241m.\u001b[39mloc[i, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEngulfing\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Bearish engulfing condition\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexing.py:1066\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1064\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m-> 1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_takeable\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py:3924\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[1;34m(self, index, col, takeable)\u001b[0m\n\u001b[0;32m   3918\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[0;32m   3920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[0;32m   3921\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[0;32m   3922\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[0;32m   3923\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n\u001b[1;32m-> 3924\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[row]\n\u001b[0;32m   3927\u001b[0m \u001b[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001b[39;00m\n\u001b[0;32m   3928\u001b[0m \u001b[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:733\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexer_at_time(key)\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# unrecognized type\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;28mself\u001b[39m, key, method, tolerance)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "data =apply_indicators(data)\n",
    "data =indicator_signal(data)\n",
    "datam = detect_consolidations_and_breakouts(data)\n",
    "data.to_csv(f'{symbol}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ba556b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['open', 'high', 'low', 'close', 'tick_volume', 'MA_daily', 'MA_weekly',\n",
       "       'RSI', 'BB_High', 'BB_Low', 'BBW', 'MACD', 'RSI_signal', 'BB_signal',\n",
       "       'MACD_signal', 'MA_signal', 'Engulfing', 'Consolidation', 'Breakout',\n",
       "       'ATR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datam.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "32557749",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[135], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming your data is in a DataFrame called datam\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Make sure your 'time' column is a datetime\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m datam[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdatam\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Set 'time' as index for the DataFrame because mplfinance requires Date index for plotting\u001b[39;00m\n\u001b[0;32m     10\u001b[0m datam\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mplfinance as mpf\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming your data is in a DataFrame called datam\n",
    "# Make sure your 'time' column is a datetime\n",
    "datam['time'] = pd.to_datetime(datam['time'])\n",
    "\n",
    "# Set 'time' as index for the DataFrame because mplfinance requires Date index for plotting\n",
    "datam.set_index('time', inplace=True)\n",
    "\n",
    "# Rename the 'tick_volume' column to 'volume'\n",
    "datam.rename(columns={'tick_volume': 'volume'}, inplace=True)\n",
    "\n",
    "# Create a dictionary for market colors\n",
    "mc = mpf.make_marketcolors(up='green',down='red',wick='inherit',edge='inherit')\n",
    "\n",
    "# Create a style based on the market colors\n",
    "s = mpf.make_mpf_style(marketcolors=mc)\n",
    "\n",
    "# Create the plot\n",
    "mpf.plot(datam, type='candle', style=s, title='Candlestick Plot', volume=True)\n",
    "\n",
    "# Add colored bars based on 'Consolidation' column\n",
    "for i in range(len(datam)):\n",
    "    if datam['Consolidation'].iloc[i] == 1:\n",
    "        plt.bar(datam.index[i], datam['high'].iloc[i], color='r')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b3521217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>MA_daily</th>\n",
       "      <th>MA_weekly</th>\n",
       "      <th>RSI</th>\n",
       "      <th>BB_High</th>\n",
       "      <th>...</th>\n",
       "      <th>BBW</th>\n",
       "      <th>MACD</th>\n",
       "      <th>RSI_signal</th>\n",
       "      <th>BB_signal</th>\n",
       "      <th>MACD_signal</th>\n",
       "      <th>MA_signal</th>\n",
       "      <th>Engulfing</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Breakout</th>\n",
       "      <th>ATR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, open, high, low, close, tick_volume, MA_daily, MA_weekly, RSI, BB_High, BB_Low, BBW, MACD, RSI_signal, BB_signal, MACD_signal, MA_signal, Engulfing, Consolidation, Breakout, ATR]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 21 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_consolidation = data[data['Breakout'] == 1]#data['Consolidation_wv']]\n",
    "\n",
    "# df_consolidation =df_consolidation[df_consolidation['Consolidation']==1]\n",
    "df_consolidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1223b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'open', 'high', 'low', 'close', 'tick_volume', 'MA_daily',\n",
       "       'MA_weekly', 'RSI', 'BB_High', 'BB_Low', 'BBW', 'MACD', 'RSI_signal',\n",
       "       'BB_signal', 'MACD_signal', 'MA_signal', 'Engulfing', 'Consolidation',\n",
       "       'Breakout', 'ATR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999809d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep learning (Python 3.10.9)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
