{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2002972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta.volatility import BollingerBands\n",
    "from ta.trend import MACD\n",
    "from ta.momentum import RSIIndicator\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d07d0b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>tick_volume</th>\n",
       "      <th>MA_daily</th>\n",
       "      <th>MA_weekly</th>\n",
       "      <th>RSI</th>\n",
       "      <th>BB_High</th>\n",
       "      <th>BB_Low</th>\n",
       "      <th>MACD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2017-01-20 11:45:00</td>\n",
       "      <td>1199.69</td>\n",
       "      <td>1200.93</td>\n",
       "      <td>1199.69</td>\n",
       "      <td>1200.88</td>\n",
       "      <td>5231</td>\n",
       "      <td>1205.0736</td>\n",
       "      <td>1170.06375</td>\n",
       "      <td>37.676300</td>\n",
       "      <td>1208.416330</td>\n",
       "      <td>1196.929670</td>\n",
       "      <td>-1.652759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2017-01-20 12:00:00</td>\n",
       "      <td>1200.88</td>\n",
       "      <td>1201.98</td>\n",
       "      <td>1200.30</td>\n",
       "      <td>1201.88</td>\n",
       "      <td>5876</td>\n",
       "      <td>1205.0126</td>\n",
       "      <td>1170.36195</td>\n",
       "      <td>44.871360</td>\n",
       "      <td>1207.376055</td>\n",
       "      <td>1197.289945</td>\n",
       "      <td>-1.463715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>2017-01-20 12:15:00</td>\n",
       "      <td>1201.88</td>\n",
       "      <td>1202.46</td>\n",
       "      <td>1201.65</td>\n",
       "      <td>1202.22</td>\n",
       "      <td>4237</td>\n",
       "      <td>1204.9654</td>\n",
       "      <td>1170.65990</td>\n",
       "      <td>47.107203</td>\n",
       "      <td>1206.365793</td>\n",
       "      <td>1197.722207</td>\n",
       "      <td>-1.271800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>2017-01-20 12:30:00</td>\n",
       "      <td>1202.22</td>\n",
       "      <td>1203.08</td>\n",
       "      <td>1201.96</td>\n",
       "      <td>1201.96</td>\n",
       "      <td>4667</td>\n",
       "      <td>1204.9214</td>\n",
       "      <td>1170.95300</td>\n",
       "      <td>45.584686</td>\n",
       "      <td>1205.654391</td>\n",
       "      <td>1197.989609</td>\n",
       "      <td>-1.127686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2017-01-20 12:45:00</td>\n",
       "      <td>1201.97</td>\n",
       "      <td>1201.98</td>\n",
       "      <td>1200.33</td>\n",
       "      <td>1200.41</td>\n",
       "      <td>5189</td>\n",
       "      <td>1204.8548</td>\n",
       "      <td>1171.23695</td>\n",
       "      <td>37.751297</td>\n",
       "      <td>1204.910847</td>\n",
       "      <td>1198.177153</td>\n",
       "      <td>-1.125573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149812</th>\n",
       "      <td>2023-06-09 19:30:00</td>\n",
       "      <td>1960.87</td>\n",
       "      <td>1961.09</td>\n",
       "      <td>1960.25</td>\n",
       "      <td>1960.65</td>\n",
       "      <td>650</td>\n",
       "      <td>1962.9322</td>\n",
       "      <td>1956.24090</td>\n",
       "      <td>43.152519</td>\n",
       "      <td>1963.540560</td>\n",
       "      <td>1960.265440</td>\n",
       "      <td>-0.602261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149813</th>\n",
       "      <td>2023-06-09 19:45:00</td>\n",
       "      <td>1960.65</td>\n",
       "      <td>1960.68</td>\n",
       "      <td>1959.68</td>\n",
       "      <td>1960.17</td>\n",
       "      <td>1032</td>\n",
       "      <td>1962.8418</td>\n",
       "      <td>1956.24880</td>\n",
       "      <td>41.397734</td>\n",
       "      <td>1963.391175</td>\n",
       "      <td>1960.090825</td>\n",
       "      <td>-0.668991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149814</th>\n",
       "      <td>2023-06-09 20:00:00</td>\n",
       "      <td>1960.18</td>\n",
       "      <td>1960.64</td>\n",
       "      <td>1960.09</td>\n",
       "      <td>1960.24</td>\n",
       "      <td>282</td>\n",
       "      <td>1962.7570</td>\n",
       "      <td>1956.26135</td>\n",
       "      <td>41.769619</td>\n",
       "      <td>1963.160226</td>\n",
       "      <td>1960.001774</td>\n",
       "      <td>-0.708065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149815</th>\n",
       "      <td>2023-06-09 20:15:00</td>\n",
       "      <td>1960.24</td>\n",
       "      <td>1960.93</td>\n",
       "      <td>1960.23</td>\n",
       "      <td>1960.85</td>\n",
       "      <td>156</td>\n",
       "      <td>1962.7108</td>\n",
       "      <td>1956.27480</td>\n",
       "      <td>45.042555</td>\n",
       "      <td>1962.979569</td>\n",
       "      <td>1959.983431</td>\n",
       "      <td>-0.681947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149816</th>\n",
       "      <td>2023-06-09 20:30:00</td>\n",
       "      <td>1960.79</td>\n",
       "      <td>1961.16</td>\n",
       "      <td>1960.58</td>\n",
       "      <td>1960.77</td>\n",
       "      <td>262</td>\n",
       "      <td>1962.7030</td>\n",
       "      <td>1956.30140</td>\n",
       "      <td>44.687805</td>\n",
       "      <td>1962.985324</td>\n",
       "      <td>1959.959676</td>\n",
       "      <td>-0.660096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149618 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       time     open     high      low    close  tick_volume  \\\n",
       "199     2017-01-20 11:45:00  1199.69  1200.93  1199.69  1200.88         5231   \n",
       "200     2017-01-20 12:00:00  1200.88  1201.98  1200.30  1201.88         5876   \n",
       "201     2017-01-20 12:15:00  1201.88  1202.46  1201.65  1202.22         4237   \n",
       "202     2017-01-20 12:30:00  1202.22  1203.08  1201.96  1201.96         4667   \n",
       "203     2017-01-20 12:45:00  1201.97  1201.98  1200.33  1200.41         5189   \n",
       "...                     ...      ...      ...      ...      ...          ...   \n",
       "149812  2023-06-09 19:30:00  1960.87  1961.09  1960.25  1960.65          650   \n",
       "149813  2023-06-09 19:45:00  1960.65  1960.68  1959.68  1960.17         1032   \n",
       "149814  2023-06-09 20:00:00  1960.18  1960.64  1960.09  1960.24          282   \n",
       "149815  2023-06-09 20:15:00  1960.24  1960.93  1960.23  1960.85          156   \n",
       "149816  2023-06-09 20:30:00  1960.79  1961.16  1960.58  1960.77          262   \n",
       "\n",
       "         MA_daily   MA_weekly        RSI      BB_High       BB_Low      MACD  \n",
       "199     1205.0736  1170.06375  37.676300  1208.416330  1196.929670 -1.652759  \n",
       "200     1205.0126  1170.36195  44.871360  1207.376055  1197.289945 -1.463715  \n",
       "201     1204.9654  1170.65990  47.107203  1206.365793  1197.722207 -1.271800  \n",
       "202     1204.9214  1170.95300  45.584686  1205.654391  1197.989609 -1.127686  \n",
       "203     1204.8548  1171.23695  37.751297  1204.910847  1198.177153 -1.125573  \n",
       "...           ...         ...        ...          ...          ...       ...  \n",
       "149812  1962.9322  1956.24090  43.152519  1963.540560  1960.265440 -0.602261  \n",
       "149813  1962.8418  1956.24880  41.397734  1963.391175  1960.090825 -0.668991  \n",
       "149814  1962.7570  1956.26135  41.769619  1963.160226  1960.001774 -0.708065  \n",
       "149815  1962.7108  1956.27480  45.042555  1962.979569  1959.983431 -0.681947  \n",
       "149816  1962.7030  1956.30140  44.687805  1962.985324  1959.959676 -0.660096  \n",
       "\n",
       "[149618 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('xauusd_M15.csv')\n",
    "\n",
    "# Calculate the moving averages\n",
    "df['MA_daily'] = df['close'].rolling(window=50).mean()\n",
    "df['MA_weekly'] = df['close'].rolling(window=200).mean()\n",
    "\n",
    "# Calculate the Relative Strength Index (RSI)\n",
    "rsi_indicator = RSIIndicator(df['close'])\n",
    "df['RSI'] = rsi_indicator.rsi()\n",
    "\n",
    "# Calculate Bollinger Bands\n",
    "bollinger = BollingerBands(df['close'])\n",
    "df['BB_High'] = bollinger.bollinger_hband()\n",
    "df['BB_Low'] = bollinger.bollinger_lband()\n",
    "\n",
    "# Calculate MACD\n",
    "macd_indicator = MACD(df['close'])\n",
    "df['MACD'] = macd_indicator.macd()\n",
    "\n",
    "# Remove nas\n",
    "data = df.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6391e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device agnostic code.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a98b2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "sequence_length = 50 \n",
    "\n",
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data.values[:, 1:]) \n",
    "\n",
    "# Convert pandas DataFrame to Tensor\n",
    "data_normalized = torch.FloatTensor(data_normalized).to(device)\n",
    "\n",
    "# Creating sequences\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+1, data.columns.get_loc('close') - 1]  # Adjusted for 0-indexing\n",
    "        inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "train_size = int(len(data_normalized) * 0.7)\n",
    "train_data = data_normalized[:train_size]\n",
    "test_data = data_normalized[train_size:]\n",
    "\n",
    "train_sequence = create_inout_sequences(train_data, sequence_length)\n",
    "test_sequence = create_inout_sequences(test_data, sequence_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b943ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataloaders\n",
    "batch_size = 64  # Feel free to adjust this\n",
    "\n",
    "train_dataloader = DataLoader(train_sequence, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_sequence, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb770be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LSTM model\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=11, hidden_layer_size=100, output_size=1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size).to(device))\n",
    "    def init_hidden(self, batch_size):\n",
    "        \n",
    "        return (torch.zeros(1, batch_size, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, batch_size, self.hidden_layer_size).to(device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions.view(input_seq.size(0), -1)\n",
    "\n",
    "\n",
    "\n",
    "# Instantiate the model, define the loss and the optimizer\n",
    "model = LSTM(input_size = 11).to(device)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2544572d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device agnostic code.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b140214",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 11, got 550",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mhidden_cell \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minit_hidden(seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))  \u001b[38;5;66;03m# initialize with batch size\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m single_loss \u001b[38;5;241m=\u001b[39m loss_function(y_pred, labels\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     12\u001b[0m single_loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[23], line 17\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input_seq)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_seq):\n\u001b[1;32m---> 17\u001b[0m     lstm_out, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_cell \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_cell\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;28mlen\u001b[39m(input_seq), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mview(input_seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[0;32m    808\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m--> 810\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    812\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[0;32m    813\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:730\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    726\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    727\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    728\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    729\u001b[0m                        ):\n\u001b[1;32m--> 730\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    732\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[0] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    734\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    216\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    220\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 11, got 550"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 150\n",
    "\n",
    "for i in range(epochs):\n",
    "    for seq, labels in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = model.init_hidden(seq.size(0))  # initialize with batch size\n",
    "\n",
    "        y_pred = model(seq.to(device))\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels.to(device))\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f87a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep learning (Python 3.10.9)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
